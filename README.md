# ğŸµ Moodify

<div align="center">

**An AI-powered mood-based music recommendation platform with face/text emotion detection and personalized Spotify playlists**

[![TypeScript](https://img.shields.io/badge/TypeScript-5.9-blue.svg)](https://www.typescriptlang.org)
[![Node.js](https://img.shields.io/badge/Node.js-20-green.svg)](https://nodejs.org)
[![Next.js](https://img.shields.io/badge/Next.js-16-black.svg)](https://nextjs.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-16-blue.svg)](https://www.postgresql.org)
[![Redis](https://img.shields.io/badge/Redis-7-red.svg)](https://redis.io)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://www.docker.com)
[![ONNX](https://img.shields.io/badge/ONNX-Inference-orange.svg)](https://onnx.ai)
[![Spotify](https://img.shields.io/badge/Spotify-API-1DB954.svg)](https://developer.spotify.com)
[![Swift](https://img.shields.io/badge/Swift-5-SwiftUI-orange.svg)](https://swift.org)

</div>

---

## ğŸ“± Overview

**Moodify** is a full-stack mood-based music recommendation system that uses AI to detect emotional state from a photo or text, then recommends songs and playlists via Spotify. Built with a microservice-oriented backend (Node.js API Gateway, FastAPI mood detection, Node.js recommendation engine), a Next.js web app, and a native **iOS app**, it demonstrates production-ready backend engineering, ML integration, and system design.

### Key Highlights

- ğŸ­ **Dual Input Modes**: Photo-based face emotion detection (ONNX) or text-based emotion (OpenAI)
- ğŸµ **Spotify Integration**: OAuth 2.0, playlist creation, track recommendations with preview URLs
- ğŸ” **Secure Auth**: JWT authentication with bcrypt password hashing, optional username and profile picture
- ğŸ³ **Dockerized Backend**: API Gateway, Mood Detection (Python), Recommendation Engine, Analytics Worker, Redis, PostgreSQL
- ğŸ¨ **Web & iOS**: Next.js App Router (Tailwind, light/dark, camera/audio) and native iOS app (Swift/SwiftUI) sharing the same APIs
- ğŸ“Š **Mood History**: Async analytics worker persists mood history; profile shows past recommendations
- â˜ï¸ **AWS-Ready**: Deploy backend on EC2 + RDS + CloudFront, frontend on Amplify (HTTPS)

---

## âœ¨ Features

### Core Functionality

- **Photo Mood Analysis**: Upload or capture a photo â†’ face detection â†’ emotion classification (ONNX) â†’ emotion-to-mood mapping â†’ Spotify recommendations
- **Text Mood Analysis**: Enter how you feel in text â†’ OpenAI text-to-emotion â†’ Spotify recommendations
- **User Accounts**: Register (email, optional username, password), login (email or username), profile with avatar and password change
- **Recommendations**: Tracks with preview URLs, optional Spotify playlist, optional AI-generated explanation (OpenAI)
- **YouTube Previews**: Optional YouTube video IDs for tracks (YouTube Data API)

### Backend & Data

- **API Gateway**: REST APIs, JWT auth, orchestration to mood-detection and recommendation-engine, mood smoothing, Redis for async jobs
- **Mood Detection**: FastAPI service; image preprocessing, ONNX inference, confidence scores; no auth/DB/Spotify
- **Recommendation Engine**: Emotionâ†’mood mapping, Spotify API (search, create playlist), OpenAI explanations, fallback logic
- **Analytics Worker**: Consumes Redis queue, writes mood history to PostgreSQL (eventually consistent)
- **PostgreSQL**: Users, recommendations, mood_history; migrations (001â€“003) for schema

### User Experience

- **Web (Next.js)**: Dashboard (hero, Analyze Photo/Text), Analyze (camera/file or text), Results (emotion, tracks, play/preview, YouTube modal), Profile (avatar, username, email, password, past recommendations), light/dark theme
- **iOS (Swift/SwiftUI)**: Login, Register, Dashboard, Analyze (camera/photo or text), Results (emotion, tracks, previews), Profile â€” same backend APIs, native UI

---

## ğŸ—ï¸ Architecture

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web / iOS      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   API Gateway    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   PostgreSQL    â”‚
â”‚  (Clients)      â”‚  REST   â”‚   (Node.js)      â”‚  HTTP   â”‚   (RDS)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                              â”‚
      â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚                    â”‚                   â”‚
      â–¼                    â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Amplify    â”‚     â”‚ Mood Detect  â”‚   â”‚ Recommendationâ”‚
â”‚  (HTTPS)    â”‚     â”‚ (FastAPI)    â”‚   â”‚ Engine        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ ONNX + CV    â”‚   â”‚ (Node.js)     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚                   â”‚
                             â”‚                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚                   â–¼              â–¼
                             â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚            â”‚  Spotify   â”‚  â”‚  OpenAI    â”‚
                             â”‚            â”‚  API       â”‚  â”‚  API       â”‚
                             â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                 â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  CloudFront  â”‚   â”‚ Redis        â”‚
             â”‚  (HTTPS)     â”‚   â”‚ (Queue/Cache)â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                 â”‚
                    â–¼                 â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  EC2         â”‚   â”‚ Analytics    â”‚
             â”‚  (Backend)   â”‚   â”‚ Worker       â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Auth**: User registers/logs in â†’ API Gateway (JWT, bcrypt) â†’ PostgreSQL `users`
2. **Photo Analyze**: Client uploads image â†’ API Gateway (auth) â†’ Mood Detection (ONNX emotion) â†’ API Gateway (smoothing) â†’ Recommendation Engine (Spotify + optional OpenAI) â†’ response with tracks
3. **Text Analyze**: Client sends text â†’ API Gateway (auth) â†’ Recommendation Engine (OpenAI text-to-emotion) â†’ Spotify recommendations â†’ response
4. **Analytics**: Mood smoothing uses Redis (recent moods per user). A separate Analytics Worker exists that would consume a queue and write to `mood_history`; see [Implementation notes](#-implementation-notes--readme-vs-code) below.

---

## ğŸ”„ Workflow (step-by-step)

*What actually happens, and what happens when something fails.*

### 1. User signs up or logs in

- **Register**: Client sends email, password (optional username). API Gateway hashes password with bcrypt, inserts into PostgreSQL `users`. Returns JWT. If email already exists â†’ 409/400.
- **Login**: Client sends email (or username) + password. API Gateway looks up user, compares password with bcrypt. If valid â†’ returns JWT; if not â†’ 401.
- **Failures**: Invalid body â†’ 400. DB down â†’ 500. JWT is used in `Authorization: Bearer <token>` for protected routes.

### 2. User uploads a photo for mood analysis

- **Request**: Web or iOS sends `POST /mood/analyze` with `multipart/form-data` (image file). **Auth required** (JWT).
- **No file**: API returns 400 "No file provided".
- **API Gateway** receives the file, reads it into a buffer, calls the **Mood Detection** service (FastAPI) at `POST /infer/mood` with the image.
- **Mood Detection**:
  - Decodes the image (invalid image â†’ raises, API Gateway returns 500).
  - Resizes if larger than max dimension.
  - **Face detection**: OpenCV Haar cascade. If **no face is found**, it still runs inference using a **center crop** of the image and returns `face_detected: false` (no error).
  - Preprocesses the crop (normalize, model input size), runs **ONNX** inference, returns `predicted_emotion`, `confidence`, `emotion_probabilities`, `face_detected`.
- **If Mood Detection fails** (timeout, crash, 5xx): API Gateway catches the error and rethrows â†’ client gets 500 "Mood detection failed".
- **API Gateway** then:
  - Pushes this mood to **Redis** (per-user list of recent emotion probabilities for **mood smoothing**).
  - Optionally loads recent moods from Redis and **averages** probabilities over a small window (smoothing).
  - Calls **Recommendation Engine** with the (possibly smoothed) emotion and confidence.

### 3. Recommendation Engine (same for photo and text flows)

- **Input**: Emotion, confidence, userId, optional emotion probabilities.
- **Low confidence**: If confidence is below a threshold (e.g. 0.4), the engine **forces neutral** mood and uses neutral recommendations (no error).
- **Emotion mapping**: Maps emotion (e.g. happy, sad, angry) to Spotify-style params (genres, energy, valence, danceability). Can **blend** from probabilities for richer mapping.
- **Spotify path**:
  - Gets an access token via **client_credentials** (server-side; no user Spotify login).
  - Calls Spotify **Recommendations API** with seed genres and target audio features.
  - If **Spotify fails** (no token, rate limit, API error): catches error and falls back (see below).
  - If Spotify succeeds: returns tracks with `preview_url` (Spotify 30s preview). **No playlist is created on Spotify**; we only get track recommendations. Optionally calls **OpenAI** for a short explanation; if OpenAI fails, explanation is omitted (no error).
- **Fallback path** (when Spotify fails or is not configured):
  - Uses **curated playlists** (hardcoded tracks per emotion). For each track, optionally calls **YouTube Data API** to get a video ID; if no API key or YouTube fails, `youtube_video_id` is just missing (track still returned with a search URL).
  - If **both Spotify and fallback** fail â†’ Recommendation Engine throws â†’ client gets 500.
- **Persistence**: For non-anonymous users, the engine writes the recommendation (user_id, emotion, track IDs) to PostgreSQL `recommendations`. There is **no API** that returns â€œpast recommendationsâ€ for the profile; the web/iOS profile â€œpast recommendationsâ€ come from **local storage** only.

### 4. User enters text for mood analysis

- **Request**: `POST /mood/analyze/text` with `{ "text": "..." }`. **No auth required**; if no user, `userId` is `"anonymous"`.
- **Recommendation Engine** calls **OpenAI** (text-to-emotion) to get an emotion and confidence. If that fails â†’ client gets 500 "Text mood analysis failed".
- Same recommendation flow as above (Spotify â†’ fallback, DB save for logged-in users).

### 5. What is *not* wired end-to-end

- **Mood history for analytics**: The **Analytics Worker** is built to consume a Redis queue and insert into `mood_history`. The **API Gateway never pushes jobs to that queue**; it only uses Redis for mood smoothing. So `mood_history` is not populated by the current flow.
- **Spotify playlist creation**: README mentions â€œplaylist creationâ€; we only **recommend** tracks. We do not create a playlist on the userâ€™s Spotify account (that would require user OAuth).
- **Profile â€œpast recommendationsâ€**: Stored in DB by the Recommendation Engine, but the API does not expose â€œmy past recommendationsâ€; the profile screen uses **local storage** only.

---

## ğŸ“‹ Implementation notes (README vs code)

| README / claim | Status |
|----------------|--------|
| Photo â†’ face detection â†’ emotion â†’ recommendations | âœ… Implemented. No-face case uses center crop, returns `face_detected: false`. |
| Text â†’ OpenAI emotion â†’ recommendations | âœ… Implemented. |
| JWT auth, bcrypt, optional username, profile picture | âœ… Implemented. |
| Mood smoothing (Redis) | âœ… Implemented (recent moods per user in Redis). |
| Spotify recommendations, preview URLs | âœ… Implemented (client_credentials; no user OAuth). |
| Optional Spotify playlist | âŒ Not implemented. We donâ€™t create a playlist on Spotify; schema has `spotify_playlist_id` but itâ€™s never set. |
| YouTube video IDs for tracks | âœ… Implemented when using **fallback** provider (YouTube Data API). Spotify path returns only `preview_url`, no `youtube_video_id`. |
| Optional AI explanation (OpenAI) | âœ… Implemented; failure is ignored and response has no explanation. |
| Analytics Worker writes mood_history | âš ï¸ Worker exists and would write to `mood_history`, but **API Gateway does not enqueue jobs** to the workerâ€™s queue; mood_history stays empty. |
| Profile â€œpast recommendationsâ€ from API | âŒ Not implemented. Past recommendations on profile are from **local storage** only. DB stores them but no endpoint returns them. |
| Text analyze requires auth | âŒ No; `/mood/analyze/text` has no auth middleware; can be called anonymously. |

---

## ğŸ› ï¸ Tech Stack

### Frontend

- **Web**: Next.js 16 (App Router), TypeScript 5, React 19, Tailwind CSS 4, next-themes (light/dark). Auth via React Context; Fetch to API Gateway (`NEXT_PUBLIC_API_URL`).
- **iOS**: Swift, SwiftUI. Views: Login, Register, Dashboard, Analyze, Results, Profile. `APIClient` + `AuthStorage`; same API Gateway base URL.

### Backend (Node.js)

- **API Gateway**: Fastify 5, JWT (jsonwebtoken), bcrypt, pg, ioredis, Zod, @fastify/cors, @fastify/multipart
- **Recommendation Engine**: Fastify 5, pg, OpenAI SDK, Axios (Spotify/YouTube)
- **Analytics Worker**: ioredis, pg, background worker loop
- **Runtime**: Node 20, TypeScript 5

### Mood Detection (Python)

- **Framework**: FastAPI 0.104, Uvicorn
- **ML**: ONNX Runtime, OpenCV, NumPy, Pillow
- **Model**: MobileNetV2-based emotion classifier (ONNX)

### Data & Infra

- **Database**: PostgreSQL 16 (users, recommendations, mood_history); migrations in `backend/migrations/`
- **Cache/Queue**: Redis 7
- **Container**: Docker, Docker Compose (`backend/docker-compose.yml`, `backend/docker-compose.aws.yml`)
- **Deploy**: AWS Amplify (web), EC2 + CloudFront (API), RDS (PostgreSQL)

---

### AWS Deployment (Summary)

- **Backend**: EC2 + RDS (PostgreSQL) + Redis on EC2; `docker-compose.aws.yml`; CloudFront in front of EC2:3002 (HTTPS); RDS SSL handled in Node (see `notes`)
- **Frontend**: Amplify, branch connected to repo, root `web`, env `NEXT_PUBLIC_API_URL` = CloudFront URL
- **Updates**: Push code â†’ EC2 `git pull`, rebuild images (`docker build --no-cache`), `docker-compose -f docker-compose.aws.yml up -d`

---

## ğŸš§ Future Enhancements

- [ ] Spotify OAuth login (use Spotify identity)
- [ ] Android app (Kotlin/Compose) reusing same backend
- [ ] Custom playlists per user stored in DB
- [ ] More emotion labels and mood mappings
- [ ] A/B testing for recommendation strategies
- [ ] Rate limiting and WAF on CloudFront
- [ ] Monitoring (CloudWatch, health dashboards)
- [ ] Path-based Amplify builds (only build when `web/` changes)

---

## ğŸ™ Acknowledgments

- **Spotify** for the Web API and OAuth
- **OpenAI** for text-to-emotion and explanations
- **ONNX** and the open-source emotion model used for face-based mood detection

---

<div align="center">

**Built with â¤ï¸ using TypeScript, Python, Next.js, SwiftUI, FastAPI, and Spotify**

â­ Star this repo if you find it helpful!

</div>
